{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCQYrXsyiOvK"
      },
      "outputs": [],
      "source": [
        "! pip install git+https://github.com/m-bain/whisperx.git\n",
        "!pip install light-the-torch\n",
        "!ltt install torch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1\n",
        "!pip install  git+https://github.com/hmmlearn/hmmlearn.git\n",
        "!pip install  git+https://github.com/pyannote/pyannote-audio.git@develop\n",
        "!pip show torch torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oB4ufmajWGr",
        "outputId": "e649cb4f-18e6-4e36-af5f-0ad2777ec2f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "# IF RUNNING ON GOOGLE COLAB, IF NOT COMMENT THIS CELL OUT!\n",
        "# from google.colab import drive\n",
        "\n",
        "# drive.mount('/gdrive')\n",
        "\n",
        "# # Google Drive root directory\n",
        "# root_path = \"/gdrive/My Drive\"\n",
        "\n",
        "# file_path = \"/gdrive/My Drive/GEHM_audio/20220916/20220916-SP05F.m4a\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULgmLH2umFv_"
      },
      "outputs": [],
      "source": [
        "# IF RUNNING LOCALLY, IF NOT COMMENT THIS CELL OUT\n",
        "\n",
        "#make sure that the is in the active directory\n",
        "\n",
        "#file_path = \"patriziaTest.wav\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlYwOwjWiSpC"
      },
      "outputs": [],
      "source": [
        "# this took 4.19s on medium.en model, with GPU A100\n",
        "# this took 4.12s on medium.en model, with GPU V100\n",
        "# this took 5.03s on medium.en model, with GPU T4\n",
        "\n",
        "# import whisperx\n",
        "\n",
        "# device = \"cuda\"\n",
        "# audio_file = file_path\n",
        "\n",
        "# # transcribe with original whisper\n",
        "# #model = whisperx.load_model(\"medium\", device) # medium is twice as fast as the large one\n",
        "# model = whisperx.load_model(\"medium\", device)\n",
        "# result = model.transcribe(audio_file)\n",
        "\n",
        "# #print(result[\"segments\"]) # before alignment\n",
        "\n",
        "# # load alignment model and metadata\n",
        "# model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
        "\n",
        "# # align whisper output\n",
        "# result_aligned = whisperx.align(result[\"segments\"], model_a, metadata, audio_file, device)\n",
        "\n",
        "#print(result_aligned[\"segments\"]) # after alignment\n",
        "#print(result_aligned[\"word_segments\"]) # after alignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "750Heov5O64k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import whisperx\n",
        "import string\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "\n",
        "data_path = '/gdrive/MyDrive/GEHM_audio/'\n",
        "all_folders = os.listdir(data_path)\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "# transcribe with original whisper\n",
        "model = whisperx.load_model(\"medium.en\", device)\n",
        "\n",
        "#print(all_folders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vq5hcZNN2p6x"
      },
      "outputs": [],
      "source": [
        "#define specific folders to process\n",
        "#all_folders = [\"20211007\", \"20220722\"]\n",
        "#print(all_folders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ6BEirBNyBB"
      },
      "outputs": [],
      "source": [
        "def create_single_speaker(audio_file_path, audio_file_index, audio_filename, current_global_xmin, current_global_xmax):\n",
        "  new_global_xmin = current_global_xmin\n",
        "  new_global_xmax = current_global_xmax\n",
        "\n",
        "  speaker_name = audio_filename.split(\"-\")[1].split(\".\")[0]\n",
        "\n",
        "  single_speaker = '\\n\\titem ['+str(audio_file_index)+']:\\n\\t\\tclass = \"IntervalTier\"\\n\\t\\tname = \"'+speaker_name+'\"'\n",
        "\n",
        "  result = model.transcribe(audio_file_path)\n",
        "  model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
        "  result_aligned = whisperx.align(result[\"segments\"], model_a, metadata, audio_file_path, device)\n",
        "  local_size = len(result_aligned[\"word_segments\"])\n",
        "\n",
        "  output = \"\"\n",
        "  for item_index, item in enumerate(result_aligned[\"word_segments\"]):\n",
        "    #print(item)\n",
        "    word = str(item['word']).translate(str.maketrans('', '', string.punctuation))\n",
        "    xmin = item['start'] if len(item)>1 else -1\n",
        "    xmax = item['end'] if len(item)>1 else -1\n",
        "\n",
        "    if xmin<current_global_xmin:\n",
        "      new_global_xmin = xmin\n",
        "    if xmax>current_global_xmax:\n",
        "      new_global_xmax = xmax\n",
        "\n",
        "    output += '\\t\\tintervals ['+str(item_index)+']:\\n\\t\\t\\txmin = '+str(xmin)+'\\n\\t\\t\\txmax = '+str(xmax)+'\\n\\t\\t\\ttext = \"'+str(word)+'\"\\n'\n",
        "\n",
        "  local_xmin = result_aligned[\"word_segments\"][0]['start']\n",
        "  local_xmax = result_aligned[\"word_segments\"][-1]['end']\n",
        "\n",
        "  single_speaker += '\\n\\t\\txmin = '+str(local_xmin)+'\\n\\t\\txmax = '+str(local_xmax)+'\\n\\t\\tintervals: size = '+str(local_size)+'\\n'\n",
        "  single_speaker += output\n",
        "\n",
        "  return single_speaker, new_global_xmin, new_global_xmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJx84MtGoL4L"
      },
      "outputs": [],
      "source": [
        "def generate_header(xmin, xmax, size):\n",
        "  header = 'File type = \"ooTextFile\"\\nObject class = \"TextGrid\"\\nxmin = '+str(xmin)+'\\nxmax = '+str(xmax)+'\\ntier? <exists>\\nsize= '+str(size)+'\\nitem []:'\n",
        "  return header"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# this is used for naming the error list file\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")"
      ],
      "metadata": {
        "id": "AS8bS8R2miOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aO8bQRc_PQAu"
      },
      "outputs": [],
      "source": [
        "failed_audios_list = []\n",
        "failed_textgrid_list = []\n",
        "for folder_index, folder in enumerate(all_folders):\n",
        "  print(\"Starting with meeting \"+str(folder) + \", \"+str(folder_index+1)+\"/\"+str(len(all_folders))+\".\")\n",
        "  audio_list = os.listdir(data_path+'/'+folder)\n",
        "\n",
        "  global_xmin = 10000\n",
        "  global_xmax = 0\n",
        "  num_of_speakers = len(audio_list)\n",
        "\n",
        "  all_speaker_results = \"\"\n",
        "  for audio_file_index, audio_filename in enumerate(audio_list):\n",
        "    print(\"Starting with audio file \"+str(audio_filename) + \", \"+str(audio_file_index+1)+\"/\"+str(len(audio_list))+\".\")\n",
        "    audio_file_path = data_path+'/'+folder+'/'+audio_filename\n",
        "    try:\n",
        "      single_speaker_output, global_xmin, global_xmax = create_single_speaker(audio_file_path, audio_file_index, audio_filename, global_xmin, global_xmax)\n",
        "      all_speaker_results += single_speaker_output\n",
        "    except:\n",
        "      print(\"Process failed for file \"+str(audio_filename))\n",
        "      failed_audios_list.append(audio_filename)\n",
        "      continue\n",
        "\n",
        "  final_output = generate_header(global_xmin, global_xmax, num_of_speakers)\n",
        "  final_output += all_speaker_results\n",
        "  try:\n",
        "    f = open(data_path+'/'+folder+'/'+folder+'_Praat.TextGrid', \"wb\")\n",
        "    f.write(final_output.encode('utf-8'))\n",
        "    f.close()\n",
        "  except:\n",
        "    print(\"Failed to write TextGrid file \"+folder+'_Praat.TextGrid')\n",
        "    failed_textgrid_list.append(folder)\n",
        "    continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ranvu2-QBjlX"
      },
      "outputs": [],
      "source": [
        "f = open(data_path+'/'+'Errors list Run '+dt_string, \"w\")\n",
        "f.write(str(failed_audios_list))\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}